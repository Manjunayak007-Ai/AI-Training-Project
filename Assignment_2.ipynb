{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Manjunayak007-Ai/AI-Training-Project/blob/main/Assignment_2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QgahpB2igBp5"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "013a07c8"
      },
      "source": [
        "# Task\n",
        "Read the file \"/content/assignment-2.txt\" to understand the requirements for creating PyTorch DataLoaders for image classification, including defining transformations, creating a custom dataset, and instantiating DataLoaders for training, validation, and testing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bcdc6ed1",
        "outputId": "699acb13-9070-464f-9143-ada8113d59a8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Assignment 2 : Image Classification with Pretrained CNNs\n",
            "\n",
            "\t1- Introduction\n",
            "\tConvolutional Neural Networks (CNNs) have achieved remarkable performance on large-scale image\n",
            "\tclassification tasks such as ImageNet. In this assignment, you will work on a 10-class classification problem using subsets of ImageNet. You are required to fine-tune pretrained models on this\n",
            "\tdataset, modify the classification head, and evaluate the performance of your models. The goal\n",
            "\tis to gain hands-on experience with transfer learning, model fine-tuning, and evaluation of deep\n",
            "\tlearning models.\n",
            "\t2- Dataset Selection and Preparation\n",
            "\tThe datasets for this assignment will be provided in a shared drive. Each student will be assigned\n",
            "\ta specific dataset number from the provided list (e.g., dataset1, dataset2, . . . , dataset10). You\n",
            "\tmust work only with the dataset assigned to you.\n",
            "\tEach dataset folder contains three subfolders:\n",
            "\t• train/ – Training images organized into class-wise folders.\n",
            "\t• val/ – Validation images (50 per class) organized into class-wise folders.\n",
            "\t• test/ – Test images organized into class-wise folders.\n",
            "\tYou are required to write a PyTorch DataLoader to load the dataset. Make sure to:\n",
            "\t\t1. Apply appropriate preprocessing and normalization (e.g., resize to 224 × 224, normalize with\n",
            "\t\tImageNet mean and standard deviation).\n",
            "\t\t2. Use data augmentation (e.g., random cropping, flipping) for the training set.\n",
            "\t\t3. Use center cropping or resizing for validation and test sets (no augmentation).\n",
            "\t\t4. Ensure that the DataLoader returns images and labels correctly for all three splits.\n",
            "\t\tYour code should clearly demonstrate how the dataset is loaded and prepared for training and\n",
            "\t\tevaluation.\n",
            "\n",
            "\t3 Experiments\n",
            "\tYou are expected to carry out the following experiments:\n",
            "\t\t1. Use the following pretrained models from PyTorch:\n",
            "\t\t• ResNet-18\n",
            "\t\t• ResNet-34\n",
            "\t\t• VGG-19\n",
            "\t\t2. Replace the classification head of each model to adapt it to the 10-class dataset.\n",
            "\t\t3. Train each model on the provided training set and validate using the validation split.\n",
            "\t\t4. Apply different hyperparameter tuning strategies (e.g., learning rate scheduling, optimizers,\n",
            "\t\tregularization).\n",
            "\t\t5. Evaluate the models on the test set and report the test accuracy as the main performance\n",
            "\t\tmetric.\n",
            "\t4 Submission Requirements\n",
            "\t• Submit a Google Colab notebook (.ipynb) with clean and well-structured PyTorch code.\n",
            "\t• The notebook should include data loading, model definition, training loop, evaluation, and\n",
            "\tplots (if any).\n",
            "\t• Save the trained models and submit the .pth files for each model (ResNet-18, ResNet-34,\n",
            "\tVGG-19).\n",
            "\t• Clearly document your hyperparameter choices and training setup in the notebook.\n",
            "\t5 Evaluation Criteria\n",
            "\t• Your performance will be evaluated based on the test accuracy of the submitted models.\n",
            "\t• A leaderboard will be created from the test accuracy of all submissions.\n",
            "\t• Code clarity, reproducibility, and proper structuring of the notebook will also be considered.\n",
            "\t• Bonus credit may be awarded for insightful analysis of hyperparameter tuning and model\n",
            "\tbehavior.\n"
          ]
        }
      ],
      "source": [
        "# Define the file path\n",
        "file_path = \"/content/assignment-2.txt\"\n",
        "\n",
        "# Read the entire content of the file\n",
        "with open(file_path, 'r') as f:\n",
        "    file_content = f.read()\n",
        "\n",
        "# Print the file content\n",
        "print(file_content)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4249ed2c"
      },
      "source": [
        "## Define transformations\n",
        "\n",
        "### Subtask:\n",
        "Define the image transformations for training, validation, and testing using `torchvision.transforms`.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a4ac2ea8"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the image transformations for training, validation, and testing as instructed.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ffc9036d",
        "outputId": "64a6782b-e0ea-402e-fb56-62f8670d4916"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train transformations defined with additional augmentation:\n",
            "Compose(\n",
            "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=True)\n",
            "    RandomCrop(size=(224, 224), padding=None)\n",
            "    RandomHorizontalFlip(p=0.5)\n",
            "    ColorJitter(brightness=(0.8, 1.2), contrast=(0.8, 1.2), saturation=(0.8, 1.2), hue=(-0.1, 0.1))\n",
            "    RandomRotation(degrees=[-15.0, 15.0], interpolation=nearest, expand=False, fill=0)\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n",
            "\n",
            "Validation and Test transformations defined:\n",
            "Compose(\n",
            "    Resize(size=256, interpolation=bilinear, max_size=None, antialias=True)\n",
            "    CenterCrop(size=(224, 224))\n",
            "    ToTensor()\n",
            "    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "import torchvision.transforms as transforms\n",
        "\n",
        "# Define transformations for the training set with data augmentation\n",
        "train_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.RandomCrop(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1), # Added ColorJitter\n",
        "    transforms.RandomRotation(degrees=15), # Added RandomRotation\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# Define transformations for the validation and test sets without data augmentation\n",
        "val_test_transforms = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "# For clarity, assign val_test_transforms to both val_transforms and test_transforms\n",
        "val_transforms = val_test_transforms\n",
        "test_transforms = val_test_transforms\n",
        "\n",
        "print(\"Train transformations defined with additional augmentation:\")\n",
        "print(train_transforms)\n",
        "print(\"\\nValidation and Test transformations defined:\")\n",
        "print(val_test_transforms)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "319817de"
      },
      "source": [
        "## Create custom dataset\n",
        "\n",
        "### Subtask:\n",
        "Create a custom PyTorch `Dataset` class to load images and labels from the dataset folders.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "10f3b8be"
      },
      "source": [
        "**Reasoning**:\n",
        "Create a custom PyTorch Dataset class to load images and labels from the dataset folders.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1fc048d2",
        "outputId": "2805e671-929b-4ee2-d85f-14a3a4322106"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "CustomImageDataset class defined successfully.\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import Dataset\n",
        "import os\n",
        "from PIL import Image\n",
        "\n",
        "class CustomImageDataset(Dataset):\n",
        "    def __init__(self, root_dir, transform=None):\n",
        "        self.root_dir = root_dir\n",
        "        self.transform = transform\n",
        "        self.image_paths = []\n",
        "        self.labels = []\n",
        "        self.classes = sorted(os.listdir(root_dir))\n",
        "        self.class_to_idx = {cls_name: i for i, cls_name in enumerate(self.classes)}\n",
        "\n",
        "        for class_name in self.classes:\n",
        "            class_dir = os.path.join(root_dir, class_name)\n",
        "            if os.path.isdir(class_dir):\n",
        "                for img_name in os.listdir(class_dir):\n",
        "                    img_path = os.path.join(class_dir, img_name)\n",
        "                    if os.path.isfile(img_path):\n",
        "                        self.image_paths.append(img_path)\n",
        "                        self.labels.append(self.class_to_idx[class_name])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.image_paths)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        img_path = self.image_paths[idx]\n",
        "        label = self.labels[idx]\n",
        "        image = Image.open(img_path).convert(\"RGB\")\n",
        "\n",
        "        if self.transform:\n",
        "            image = self.transform(image)\n",
        "\n",
        "        return image, label\n",
        "\n",
        "print(\"CustomImageDataset class defined successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d9eef766"
      },
      "source": [
        "## Instantiate datasets\n",
        "\n",
        "### Subtask:\n",
        "Create instances of the custom dataset for the training, validation, and test sets with the defined transformations.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0f098301"
      },
      "source": [
        "**Reasoning**:\n",
        "Create instances of the custom dataset for the training, validation, and test sets using the defined transformations and print the size of each dataset.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99vjRLVmcX_2",
        "outputId": "3772c811-1845-40bd-d608-a5b407de4513"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cb33c12c",
        "outputId": "909c88e6-e4bc-46e3-81fd-c954af004aa7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of samples in training dataset: 11250\n",
            "Number of samples in validation dataset: 450\n"
          ]
        }
      ],
      "source": [
        "# Define the base directory for the dataset\n",
        "# Replace \"path/to/your/dataset\" with the actual path to your dataset folder\n",
        "# Example: base_dir = \"/content/my_image_dataset\"\n",
        "base_dir = \"/content/drive/My Drive/dataset4\" # <<< !!! IMPORTANT: Replace this with your actual dataset path\n",
        "\n",
        "# Create dataset instances for training, validation, and testing\n",
        "train_dataset = CustomImageDataset(root_dir=os.path.join(base_dir, 'train'), transform=train_transforms)\n",
        "val_dataset = CustomImageDataset(root_dir=os.path.join(base_dir, 'val'), transform=val_transforms)\n",
        "#test_dataset = CustomImageDataset(root_dir=os.path.join(base_dir, 'test'), transform=test_transforms)\n",
        "\n",
        "# Print the number of samples in each dataset\n",
        "print(f\"Number of samples in training dataset: {len(train_dataset)}\")\n",
        "print(f\"Number of samples in validation dataset: {len(val_dataset)}\")\n",
        "#print(f\"Number of samples in test dataset: {len(test_dataset)}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6479d1c3"
      },
      "source": [
        "## Create DataLoaders\n",
        "\n",
        "### Subtask:\n",
        "Create PyTorch `DataLoader` instances for the training, validation, and test sets."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ba02068e"
      },
      "source": [
        "**Reasoning**:\n",
        "Create PyTorch `DataLoader` instances for the training, validation, and test sets using the instantiated datasets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "743b2c2b",
        "outputId": "bf06b8ca-a973-4d02-ae79-a572f6465f71"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train DataLoader created with batch size 64\n",
            "Validation DataLoader created with batch size 64\n"
          ]
        }
      ],
      "source": [
        "from torch.utils.data import DataLoader\n",
        "\n",
        "# Define batch size (you can adjust this)\n",
        "batch_size = 64\n",
        "\n",
        "# Create DataLoaders for training, validation, and testing\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True,num_workers=2)\n",
        "val_dataloader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False,num_workers=2)\n",
        "#test_dataloader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
        "\n",
        "print(f\"Train DataLoader created with batch size {batch_size}\")\n",
        "print(f\"Validation DataLoader created with batch size {batch_size}\")\n",
        "#print(f\"Test DataLoader created with batch size {batch_size}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ec7f2485"
      },
      "source": [
        "## Verify DataLoaders\n",
        "\n",
        "### Subtask:\n",
        "Fetch a batch of data from the training DataLoader and display the shapes of the images and labels."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5a2f9e62"
      },
      "source": [
        "**Reasoning**:\n",
        "Verify that the DataLoaders are working correctly by fetching a batch of data from the training DataLoader and displaying the shapes of the images and labels."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9bf08eff",
        "outputId": "3fae895e-d31a-472d-d651-5f1814a24b1a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of images batch: torch.Size([64, 3, 224, 224])\n",
            "Shape of labels batch: torch.Size([64])\n"
          ]
        }
      ],
      "source": [
        "# Fetch a batch of data from the training DataLoader\n",
        "images, labels = next(iter(train_dataloader))\n",
        "\n",
        "# Print the shapes of the images and labels\n",
        "print(f\"Shape of images batch: {images.shape}\")\n",
        "print(f\"Shape of labels batch: {labels.shape}\")\n",
        "\n",
        "# Display the first image in the batch (optional)\n",
        "# import matplotlib.pyplot as plt\n",
        "# import numpy as np\n",
        "#\n",
        "# # Helper function to show a batch of images\n",
        "# def show_images(imgs):\n",
        "#     grid = torchvision.utils.make_grid(imgs)\n",
        "#     plt.imshow(grid.numpy().transpose((1, 2, 0)))\n",
        "#     plt.title('Image Batch')\n",
        "#     plt.axis('off')\n",
        "#     plt.show()\n",
        "#\n",
        "# # Denormalize and show the first image\n",
        "# # mean = np.array([0.485, 0.456, 0.406])\n",
        "# # std = np.array([0.229, 0.224, 0.225])\n",
        "# # img = images[0].numpy().transpose((1, 2, 0))\n",
        "# # img = std * img + mean\n",
        "# # img = np.clip(img, 0, 1)\n",
        "# # plt.imshow(img)\n",
        "# # plt.title(f\"Label: {labels[0].item()}\")\n",
        "# # plt.axis('off')\n",
        "# # plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d96b1bcc"
      },
      "source": [
        "# Task\n",
        "Train and evaluate ResNet-18, ResNet-34, and VGG-19 models on the dataset located at \"https://drive.google.com/drive/u/1/folders/1TnY_KitjtNLrC3qkjGM-v1CQEh4T9Jbg\", following the requirements in \"/content/assignment-2.txt\". Comment out the test dataset part as it doesn't exist."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6c251a1b"
      },
      "source": [
        "## Load pretrained models\n",
        "\n",
        "### Subtask:\n",
        "Load the specified pretrained models (ResNet-18, ResNet-34, VGG-19) from PyTorch.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1be4a5da"
      },
      "source": [
        "**Reasoning**:\n",
        "Load the specified pretrained models (ResNet-18, ResNet-34, VGG-19) from PyTorch.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a07ae4bb",
        "outputId": "ab1c6446-1d85-47ae-d82f-3e2a5f7e1a00"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet18_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet18_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=ResNet34_Weights.IMAGENET1K_V1`. You can also use `weights=ResNet34_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n",
            "/usr/local/lib/python3.12/dist-packages/torchvision/models/_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG19_Weights.IMAGENET1K_V1`. You can also use `weights=VGG19_Weights.DEFAULT` to get the most up-to-date weights.\n",
            "  warnings.warn(msg)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrained ResNet-18, ResNet-34, and VGG-19 models loaded successfully.\n"
          ]
        }
      ],
      "source": [
        "import torchvision.models as models\n",
        "\n",
        "# Load pretrained ResNet-18 model\n",
        "resnet18_model = models.resnet18(pretrained=True)\n",
        "\n",
        "# Load pretrained ResNet-34 model\n",
        "resnet34_model = models.resnet34(pretrained=True)\n",
        "\n",
        "# Load pretrained VGG-19 model\n",
        "vgg19_model = models.vgg19(pretrained=True)\n",
        "\n",
        "print(\"Pretrained ResNet-18, ResNet-34, and VGG-19 models loaded successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ce1fb4c6"
      },
      "source": [
        "## Modify Classification Head\n",
        "\n",
        "### Subtask:\n",
        "Replace the classification head of each model to adapt it to the 10-class dataset."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b8365b7a"
      },
      "source": [
        "**Reasoning**:\n",
        "Replace the classification head of each model to adapt it to the 10-class dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fa99bd2b",
        "outputId": "1a8d9a4b-eaad-4e52-e8ad-9feea0093453"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification heads modified successfully, increased Dropout for ResNet-18.\n"
          ]
        }
      ],
      "source": [
        "import torch.nn as nn\n",
        "\n",
        "num_classes = 10 # Based on the assignment description\n",
        "\n",
        "# Modify ResNet-18 classification head and add Dropout\n",
        "# Access the input features of the original fully connected layer\n",
        "# Check if resnet18_model.fc is already a Sequential, if so, access the Linear layer within it\n",
        "if isinstance(resnet18_model.fc, nn.Sequential):\n",
        "    num_ftrs_resnet18 = resnet18_model.fc[1].in_features # Access the Linear layer after Dropout\n",
        "else:\n",
        "    num_ftrs_resnet18 = resnet18_model.fc.in_features # Access the original Linear layer\n",
        "\n",
        "# Replace the fully connected layer with a Sequential block including Dropout\n",
        "resnet18_model.fc = nn.Sequential(\n",
        "    nn.Dropout(0.3), # Reduced Dropout rate to 0.3\n",
        "    nn.Linear(num_ftrs_resnet18, num_classes)\n",
        ")\n",
        "\n",
        "\n",
        "# Modify ResNet-34 classification head\n",
        "num_ftrs_resnet34 = resnet34_model.fc.in_features\n",
        "resnet34_model.fc = nn.Linear(num_ftrs_resnet34, num_classes)\n",
        "\n",
        "# Modify VGG-19 classification head\n",
        "# VGG's classifier is a sequence of linear layers\n",
        "num_ftrs_vgg19 = vgg19_model.classifier[6].in_features\n",
        "vgg19_model.classifier[6] = nn.Linear(num_ftrs_vgg19, num_classes)\n",
        "\n",
        "print(\"Classification heads modified successfully, increased Dropout for ResNet-18.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d6124292"
      },
      "source": [
        "## Define Training Components\n",
        "\n",
        "### Subtask:\n",
        "Define the loss function, optimizer, and optionally a learning rate scheduler."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0130f4bc"
      },
      "source": [
        "**Reasoning**:\n",
        "Define the loss function, optimizer, and optionally a learning rate scheduler."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 43,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abc568d8",
        "outputId": "270ed270-0269-4dfb-d8b7-f284bd26258b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training components (Loss function, Optimizers, and Schedulers) defined successfully.\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the loss function (Cross-Entropy Loss is common for classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizers for each model\n",
        "# You can choose different optimizers or hyperparameters here\n",
        "optimizer_resnet18 = optim.SGD(resnet18_model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_resnet34 = optim.SGD(resnet34_model.parameters(), lr=0.001, momentum=0.9)\n",
        "optimizer_vgg19 = optim.SGD(vgg19_model.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Define learning rate schedulers (optional but recommended)\n",
        "# Example: StepLR decays the learning rate by a factor of 0.1 every 7 epochs\n",
        "scheduler_resnet18 = lr_scheduler.StepLR(optimizer_resnet18, step_size=3, gamma=0.1)\n",
        "scheduler_resnet34 = lr_scheduler.StepLR(optimizer_resnet34, step_size=3, gamma=0.1)\n",
        "scheduler_vgg19 = lr_scheduler.StepLR(optimizer_vgg19, step_size=3, gamma=0.1)\n",
        "\n",
        "print(\"Training components (Loss function, Optimizers, and Schedulers) defined successfully.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "de3d2227"
      },
      "source": [
        "## Implement Training and Validation Loops\n",
        "\n",
        "### Subtask:\n",
        "Write the code for training each model and validating its performance on the validation set."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a7333672"
      },
      "source": [
        "**Reasoning**:\n",
        "Write the code for a training and validation loop function that can be reused for all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 44,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "78977812",
        "outputId": "c6460f75-853b-40cf-863b-277314eaf4da"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training function 'train_model' modified to return history.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "import copy\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=25, device='cuda'):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # To store history of loss and accuracy\n",
        "    train_loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_loss_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    outputs = model(inputs)\n",
        "                    _, preds = torch.max(outputs, 1)\n",
        "                    loss = criterion(outputs, labels)\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        loss.backward()\n",
        "                        optimizer.step()\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataloader.dataset)\n",
        "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Store history\n",
        "            if phase == 'train':\n",
        "                train_loss_history.append(epoch_loss)\n",
        "                train_acc_history.append(epoch_acc.item()) # Convert to float for plotting\n",
        "            else:\n",
        "                val_loss_history.append(epoch_loss)\n",
        "                val_acc_history.append(epoch_acc.item()) # Convert to float for plotting\n",
        "\n",
        "\n",
        "            # deep copy the model if it's the best accuracy\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:.4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, train_loss_history, train_acc_history, val_loss_history, val_acc_history\n",
        "\n",
        "print(\"Training function 'train_model' modified to return history.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "50a6412c"
      },
      "source": [
        "## Implement Evaluation\n",
        "\n",
        "### Subtask:\n",
        "Write the code to evaluate the trained models on the test set (if available) and report the accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bea832e3"
      },
      "source": [
        "**Reasoning**:\n",
        "Write the code for an evaluation function that can be reused for all models."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18e3b8e1",
        "outputId": "e441b291-8cc5-4722-c347-670f8d5aa8b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Evaluation function 'evaluate_model' defined.\n"
          ]
        }
      ],
      "source": [
        "def evaluate_model(model, dataloader, device='cuda'):\n",
        "    model.eval()  # Set model to evaluate mode\n",
        "    running_corrects = 0\n",
        "    total_samples = 0\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for inputs, labels in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            running_corrects += torch.sum(preds == labels.data)\n",
        "            total_samples += labels.size(0)\n",
        "\n",
        "    accuracy = running_corrects.double() / total_samples\n",
        "\n",
        "    print(f'Accuracy: {accuracy:.4f}')\n",
        "    return accuracy\n",
        "\n",
        "print(\"Evaluation function 'evaluate_model' defined.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6cf46ad8"
      },
      "source": [
        "## Train and Evaluate Models\n",
        "\n",
        "### Subtask:\n",
        "Train each of the modified pretrained models and evaluate their performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5c755137"
      },
      "source": [
        "**Reasoning**:\n",
        "Train each of the modified pretrained models and evaluate their performance."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 497
        },
        "id": "6396d90c",
        "outputId": "2d98e390-1e71-4472-f0e8-657ff160a3df"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "\n",
            "Training ResNet-18:\n",
            "Epoch 0/9\n",
            "----------\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3726483927.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Train ResNet-18\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\nTraining ResNet-18:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mresnet18_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresnet18_model\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_resnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscheduler_resnet18\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# Reduced epochs for demonstration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# Evaluate ResNet-18 on the validation set\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-2586088046.py\u001b[0m in \u001b[0;36mtrain_model\u001b[0;34m(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs, device)\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     35\u001b[0m             \u001b[0;31m# Iterate over data.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 36\u001b[0;31m             \u001b[0;32mfor\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdataloader\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     37\u001b[0m                 \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     38\u001b[0m                 \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    732\u001b[0m                 \u001b[0;31m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    733\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_reset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[call-arg]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 734\u001b[0;31m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    735\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_num_yielded\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    736\u001b[0m             if (\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/dataloader.py\u001b[0m in \u001b[0;36m_next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    788\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_next_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mindex\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_next_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 790\u001b[0;31m         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_dataset_fetcher\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfetch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# may raise StopIteration\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    791\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    792\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpin_memory\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_pin_memory_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/utils/data/_utils/fetch.py\u001b[0m in \u001b[0;36mfetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     50\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__getitems__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0midx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m             \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdataset\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mpossibly_batched_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/ipython-input-1208262498.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0mimg_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimage_paths\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m         \u001b[0mlabel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0midx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m         \u001b[0mimage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimg_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"RGB\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/PIL/Image.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(fp, mode, formats)\u001b[0m\n\u001b[1;32m   3522\u001b[0m         \u001b[0mexclusive_fp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3524\u001b[0;31m     \u001b[0mprefix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3525\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3526\u001b[0m     \u001b[0mpreinit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "# Set device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Train ResNet-18\n",
        "print(\"\\nTraining ResNet-18:\")\n",
        "resnet18_model = train_model(resnet18_model, criterion, optimizer_resnet18, scheduler_resnet18, train_dataloader, val_dataloader, num_epochs=10, device=device) # Reduced epochs for demonstration\n",
        "\n",
        "# Evaluate ResNet-18 on the validation set\n",
        "print(\"\\nEvaluating ResNet-18 on validation set:\")\n",
        "evaluate_model(resnet18_model, val_dataloader, device=device)\n",
        "\n",
        "# Train ResNet-34\n",
        "print(\"\\nTraining ResNet-34:\")\n",
        "resnet34_model = train_model(resnet34_model, criterion, optimizer_resnet34, scheduler_resnet34, train_dataloader, val_dataloader, num_epochs=10, device=device) # Reduced epochs for demonstration\n",
        "\n",
        "# Evaluate ResNet-34 on the validation set\n",
        "print(\"\\nEvaluating ResNet-34 on validation set:\")\n",
        "evaluate_model(resnet34_model, val_dataloader, device=device)\n",
        "\n",
        "# Train VGG-19\n",
        "print(\"\\nTraining VGG-19:\")\n",
        "vgg19_model = train_model(vgg19_model, criterion, optimizer_vgg19, scheduler_vgg19, train_dataloader, val_dataloader, num_epochs=10, device=device) # Reduced epochs for demonstration\n",
        "\n",
        "# Evaluate VGG-19 on the validation set\n",
        "print(\"\\nEvaluating VGG-19 on validation set:\")\n",
        "evaluate_model(vgg19_model, val_dataloader, device=device)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "52735aac"
      },
      "source": [
        "## Adjust Hyperparameters and Retrain\n",
        "\n",
        "### Subtask:\n",
        "Adjust the learning rate and add weight decay to the optimizers and retrain the models to evaluate the impact on overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bbf123b0"
      },
      "source": [
        "**Reasoning**:\n",
        "Adjust the learning rate and add weight decay to the optimizers and retrain the models to evaluate the impact on overfitting."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3f4f7ae1",
        "outputId": "3b5539ee-dbc9-4048-8998-e8ad707c189d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training components (Loss function, Optimizers, and Schedulers) redefined with adjusted hyperparameters.\n"
          ]
        }
      ],
      "source": [
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn as nn\n",
        "\n",
        "# Define the loss function (Cross-Entropy Loss is common for classification)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# Define optimizers for each model\n",
        "# You can choose different optimizers or hyperparameters here\n",
        "# Adjusted learning rate and added weight decay to combat overfitting\n",
        "optimizer_resnet18 = optim.Adam(resnet18_model.parameters(), lr=0.001, weight_decay=1e-3) # Switched to Adam optimizer\n",
        "optimizer_resnet34 = optim.Adam(resnet34_model.parameters(), lr=0.001, weight_decay=1e-3) # Switched to Adam optimizer\n",
        "optimizer_vgg19 = optim.Adam(vgg19_model.parameters(), lr=0.001, weight_decay=1e-3) # Reverted VGG-19 learning rate to 0.001\n",
        "\n",
        "\n",
        "# Define learning rate schedulers (optional but recommended)\n",
        "# Example: StepLR decays the learning rate by a factor of 0.1 every 7 epochs\n",
        "scheduler_resnet18 = lr_scheduler.StepLR(optimizer_resnet18, step_size=7, gamma=0.1)\n",
        "scheduler_resnet34 = lr_scheduler.StepLR(optimizer_resnet34, step_size=7, gamma=0.1)\n",
        "scheduler_vgg19 = lr_scheduler.StepLR(optimizer_vgg19, step_size=7, gamma=0.1)\n",
        "\n",
        "print(\"Training components (Loss function, Optimizers, and Schedulers) redefined with adjusted hyperparameters.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8e5adb00"
      },
      "source": [
        "## Save Trained Models\n",
        "\n",
        "### Subtask:\n",
        "Save the state dictionary of the trained ResNet-18, ResNet-34, and VGG-19 models to .pth files."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abf35ad7"
      },
      "source": [
        "**Reasoning**:\n",
        "Save the state dictionary of each trained model as required by the assignment for submission."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2499d3f6",
        "outputId": "8582175f-9717-4090-ddbc-b9607cd7a0e9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Trained models saved to /content/drive/My Drive/trained_models\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import os\n",
        "\n",
        "# Define the directory to save the models\n",
        "# You might want to change this path to a specific folder in your Google Drive\n",
        "save_dir = \"/content/drive/My Drive/trained_models\"\n",
        "os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "# Save the state dictionary of each model\n",
        "torch.save(resnet18_model.state_dict(), os.path.join(save_dir, 'resnet18_model.pth'))\n",
        "torch.save(resnet34_model.state_dict(), os.path.join(save_dir, 'resnet34_model.pth'))\n",
        "torch.save(vgg19_model.state_dict(), os.path.join(save_dir, 'vgg19_model.pth'))\n",
        "\n",
        "print(f\"Trained models saved to {save_dir}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8f8f4b61"
      },
      "source": [
        "**Reasoning**:\n",
        "Retrain each model with the adjusted hyperparameters to evaluate their impact on performance and overfitting."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "020b1fa0"
      },
      "source": [
        "## Recreated: Modify Training Loop for Mixup and Checkpointing\n",
        "\n",
        "### Subtask:\n",
        "Recreate the `train_model` function with Mixup integration and checkpoint saving."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "987f9235"
      },
      "source": [
        "**Reasoning**:\n",
        "Recreate the `train_model` function to ensure the latest version with Mixup and checkpointing is available for use."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ce85b771",
        "outputId": "f0c34636-e322-451d-848c-93eef1dad553"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training function 'train_model' updated to use torch.amp.\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import time\n",
        "import copy\n",
        "import numpy as np\n",
        "import os\n",
        "import torch.amp as amp # Import amp from torch.amp\n",
        "\n",
        "def train_model(model, criterion, optimizer, scheduler, train_loader, val_loader, num_epochs=25, device='cuda', use_mixup=True, mixup_alpha=1.0, save_dir=None):\n",
        "    since = time.time()\n",
        "\n",
        "    best_model_wts = copy.deepcopy(model.state_dict())\n",
        "    best_acc = 0.0\n",
        "\n",
        "    # To store history of loss and accuracy\n",
        "    train_loss_history = []\n",
        "    train_acc_history = []\n",
        "    val_loss_history = []\n",
        "    val_acc_history = []\n",
        "\n",
        "    model.to(device)\n",
        "\n",
        "    # Initialize GradScaler for mixed precision\n",
        "    scaler = amp.GradScaler('cuda') # Use 'cuda' argument\n",
        "\n",
        "    # Create save directory if it doesn't exist\n",
        "    if save_dir and not os.path.exists(save_dir):\n",
        "        os.makedirs(save_dir)\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        # Each epoch has a training and validation phase\n",
        "        for phase in ['train', 'val']:\n",
        "            if phase == 'train':\n",
        "                model.train()  # Set model to training mode\n",
        "                dataloader = train_loader\n",
        "            else:\n",
        "                model.eval()   # Set model to evaluate mode\n",
        "                dataloader = val_loader\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "            total_samples = 0\n",
        "\n",
        "            # Iterate over data.\n",
        "            for inputs, labels in dataloader:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                # zero the parameter gradients\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "                # forward\n",
        "                # track history if only in train\n",
        "                with torch.set_grad_enabled(phase == 'train'):\n",
        "                    # Use autocast for mixed precision\n",
        "                    with amp.autocast('cuda'): # Use 'cuda' argument\n",
        "                        if phase == 'train' and use_mixup:\n",
        "                            inputs, targets_a, targets_b, lam = mixup_data(inputs, labels, mixup_alpha, device)\n",
        "                            outputs = model(inputs)\n",
        "                            loss = mixup_criterion(criterion, outputs, targets_a, targets_b, lam)\n",
        "                            _, preds = torch.max(outputs, 1)\n",
        "                            corrects = (lam * preds.eq(targets_a.data).sum().item() + (1 - lam) * preds.eq(targets_b.data).sum().item())\n",
        "\n",
        "                        else:\n",
        "                            outputs = model(inputs)\n",
        "                            _, preds = torch.max(outputs, 1)\n",
        "                            loss = criterion(outputs, labels)\n",
        "                            corrects = torch.sum(preds == labels.data)\n",
        "\n",
        "\n",
        "                    # backward + optimize only if in training phase\n",
        "                    if phase == 'train':\n",
        "                        # Scale the loss and call backward()\n",
        "                        scaler.scale(loss).backward()\n",
        "                        # Unscale gradients and call optimizer.step()\n",
        "                        scaler.step(optimizer)\n",
        "                        # Update the scale for next iteration\n",
        "                        scaler.update()\n",
        "\n",
        "\n",
        "                # statistics\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                if phase == 'train' and use_mixup:\n",
        "                     running_corrects += corrects\n",
        "                else:\n",
        "                     running_corrects += corrects.item()\n",
        "\n",
        "                total_samples += inputs.size(0)\n",
        "\n",
        "\n",
        "            if phase == 'train':\n",
        "                scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / total_samples\n",
        "            epoch_acc = running_corrects / total_samples\n",
        "\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "            # Store history\n",
        "            if phase == 'train':\n",
        "                train_loss_history.append(epoch_loss)\n",
        "                train_acc_history.append(epoch_acc)\n",
        "            else:\n",
        "                val_loss_history.append(epoch_loss)\n",
        "                val_acc_history.append(epoch_acc)\n",
        "\n",
        "\n",
        "            # deep copy the model if it's the best accuracy and save checkpoint\n",
        "            if phase == 'val' and epoch_acc > best_acc:\n",
        "                best_acc = epoch_acc\n",
        "                best_model_wts = copy.deepcopy(model.state_dict())\n",
        "                if save_dir:\n",
        "                    model_name = model.__class__.__name__ # Get model class name\n",
        "                    save_path = os.path.join(save_dir, f'{model_name}_best_val_acc.pth')\n",
        "                    torch.save(model.state_dict(), save_path)\n",
        "                    print(f\"Saved best model checkpoint to {save_path}\")\n",
        "\n",
        "\n",
        "        print()\n",
        "\n",
        "    time_elapsed = time.time() - since\n",
        "    print(f'Training complete in {time_elapsed // 60:.0f}m {time_elapsed % 60:.0f}s')\n",
        "    print(f'Best val Acc: {best_acc:.4f}')\n",
        "\n",
        "    # load best model weights\n",
        "    model.load_state_dict(best_model_wts)\n",
        "\n",
        "    return model, train_loss_history, train_acc_history, val_loss_history, val_acc_history\n",
        "\n",
        "print(\"Training function 'train_model' updated to use torch.amp.\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "L6fogO-UXj_K"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch # Make sure torch is imported here too\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0, device='cuda'):\n",
        "    '''Returns mixed inputs, pairs of targets, and lambda'''\n",
        "    if alpha > 0:\n",
        "        lam = np.random.beta(alpha, alpha)\n",
        "    else:\n",
        "        lam = 1\n",
        "\n",
        "    batch_size = x.size()[0]\n",
        "    index = torch.randperm(batch_size).to(device)\n",
        "\n",
        "    mixed_x = lam * x + (1 - lam) * x[index, :]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
        "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d0cae981"
      },
      "source": [
        "## Retrain Models on Full Dataset with Enhanced Augmentation, Stronger Regularization, and Mixup (Fourth Pass)\n",
        "\n",
        "### Subtask:\n",
        "Retrain each model on the full training and validation datasets with enhanced per-image augmentation, current Adam settings (including increased weight decay), and Mixup data augmentation."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51673a77"
      },
      "source": [
        "**Reasoning**:\n",
        "Retrain each model on the full dataset with enhanced data augmentation and stronger regularization to further combat severe overfitting and evaluate the impact on validation accuracy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a05cd694",
        "outputId": "abf6bd34-3f86-4510-c1b0-89a1580f17bc"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using device: cuda\n",
            "Focusing on training ResNet-18 on full training dataset of size 11250 and validation dataset of size 450 with enhanced augmentation and current regularization settings.\n",
            "\n",
            "Retraining ResNet-18:\n",
            "Epoch 0/4\n",
            "----------\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import torch.nn as nn\n",
        "\n",
        "# Ensure models are on the correct device and reinitialize optimizers/schedulers\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "print(f\"Using device: {device}\")\n",
        "\n",
        "# Re-define optimizers and schedulers with Adam optimizer and current weight decay\n",
        "# This is necessary because the previous training modified the model parameters\n",
        "# and the optimizers need to be re-initialized with the new parameters\n",
        "optimizer_resnet18 = optim.Adam(resnet18_model.parameters(), lr=0.0001, weight_decay=1e-4) # ResNet-18 with reduced LR and reduced WD to 1e-4\n",
        "optimizer_resnet34 = optim.Adam(resnet34_model.parameters(), lr=0.001, weight_decay=1e-3) # ResNet-34 with original weight decay\n",
        "optimizer_vgg19 = optim.Adam(vgg19_model.parameters(), lr=0.001, weight_decay=1e-3) # VGG-19 with original weight decay\n",
        "\n",
        "scheduler_resnet18 = lr_scheduler.StepLR(optimizer_resnet18, step_size=3, gamma=0.1) # Adjusted step_size\n",
        "scheduler_resnet34 = lr_scheduler.StepLR(optimizer_resnet34, step_size=3, gamma=0.1) # Adjusted step_size\n",
        "scheduler_vgg19 = lr_scheduler.StepLR(optimizer_vgg19, step_size=3, gamma=0.1) # Adjusted step_size\n",
        "\n",
        "\n",
        "print(f\"Focusing on training ResNet-18 on full training dataset of size {len(train_dataset)} and validation dataset of size {len(val_dataset)} with enhanced augmentation and current regularization settings.\")\n",
        "\n",
        "\n",
        "# Train ResNet-18 with enhanced augmentation and current regularization\n",
        "print(\"\\nRetraining ResNet-18:\")\n",
        "resnet18_model, resnet18_train_loss, resnet18_train_acc, resnet18_val_loss, resnet18_val_acc = train_model(\n",
        "    resnet18_model, criterion, optimizer_resnet18, scheduler_resnet18, train_dataloader, val_dataloader, num_epochs=5, device=device, use_mixup=True) # Reduced epochs to 5\n",
        "\n",
        "# Evaluate Retrained ResNet-18 on the validation set\n",
        "print(\"\\nEvaluating Retrained ResNet-18 on validation set:\")\n",
        "evaluate_model(resnet18_model, val_dataloader, device=device)\n",
        "\n",
        "# Train ResNet-34 with enhanced augmentation and current regularization\n",
        "# print(\"\\nRetraining ResNet-34:\")\n",
        "# resnet34_model, resnet34_train_loss, resnet34_train_acc, resnet34_val_loss, resnet34_val_acc = train_model(\n",
        "# #     resnet34_model, criterion, optimizer_resnet34, scheduler_resnet34, train_dataloader, val_dataloader, num_epochs=5, device=device, use_mixup=True) # Using full dataloaders, enhanced augmentation (via train_transforms), and Mixup\n",
        "\n",
        "# Evaluate Retrained ResNet-34 on the validation set\n",
        "# print(\"\\nEvaluating Retrained ResNet-34 on validation set:\")\n",
        "# evaluate_model(resnet34_model, val_dataloader, device=device)\n",
        "\n",
        "# Train VGG-19 with enhanced augmentation and current regularization\n",
        "# print(\"\\nRetraining VGG-19:\")\n",
        "# vgg19_model, vgg19_train_loss, vgg19_train_acc, vgg19_val_loss, vgg19_val_acc = train_model(\n",
        "#     vgg19_model, criterion, optimizer_vgg19, scheduler_vgg19, train_dataloader, val_dataloader, num_epochs=5, device=device, use_mixup=True) # Using full dataloaders, enhanced augmentation (via train_transforms), and Mixup\n",
        "\n",
        "# Evaluate Retrained VGG-19 on the validation set\n",
        "# print(\"\\nEvaluating Retrained VGG-19 on validation set:\")\n",
        "# evaluate_model(vgg19_model, val_dataloader, device=device)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}